{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a05fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flowsig as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0de15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata = sc.read('onc_flowsig.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc13 = adata[adata.obs['orig.ident'].isin(['onc1','onc3']), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bce06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12 = sc.read('onc_lif12.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12 = adata[adata.obs['orig.ident'].isin(['onc1','onc2']), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_key = 'orig.ident'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellchat_Ctrl = pd.read_csv('communications_ctrl.csv')\n",
    "cellchat_Onc2h = pd.read_csv('communications_onc2h.csv')\n",
    "cellchat_Onc8h = pd.read_csv('communications_onc8h.csv')\n",
    "cellchat_Onc1d = pd.read_csv('communications_onc1d.csv')\n",
    "cellchat_Onc3d = pd.read_csv('communications_onc3d.csv')\n",
    "cellchat_Onc7d = pd.read_csv('communications_onc7d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellchat_output_key = 'cellchat_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[cellchat_output_key] = {'onc1': cellchat_Ctrl,  'onc2': cellchat_Onc2h,  'onc3': cellchat_Onc8h,  'onc4': cellchat_Onc1d,  'onc5': cellchat_Onc3d,  'onc6': cellchat_Onc7d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3249e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12.uns[cellchat_output_key] = {'onc1': cellchat_Ctrl,  'onc2': cellchat_Onc2h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103821b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('onc_gem0422.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.pp.construct_flow_expressions(adata,\n",
    "                                cellchat_output_key=cellchat_output_key,\n",
    "                                model_organism = 'mouse',\n",
    "                                spatial = False,\n",
    "                                method = 'cellchat'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9123fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 提取 GEM 表达\n",
    "gems = pd.DataFrame(adata.obsm['X_gem'], \n",
    "                    columns=[f'GEM{i+1}' for i in range(adata.obsm['X_gem'].shape[1])],\n",
    "                    index=adata.obs_names)  # 保留细胞 ID 为行名\n",
    "\n",
    "# 添加 index 列（供 R 中合并）\n",
    "gems.reset_index(inplace=True)\n",
    "gems.rename(columns={'index': 'cell_id'}, inplace=True)\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "gems.to_csv(\"adata_X_gem.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eea9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flowsig.preprocessing._flow_expressions import (\n",
    "    construct_outflow_signals_cellchat,\n",
    "    construct_inflow_signals_cellchat,\n",
    "    construct_gem_expressions,\n",
    "    FlowSigConfig\n",
    ")\n",
    "\n",
    "# 1. Outflow\n",
    "adata_outflow, _ = construct_outflow_signals_cellchat(\n",
    "    adata, cellchat_output_key=cellchat_output_key\n",
    ")\n",
    "print(\"OUTFLOW .var columns:\", adata_outflow.var.columns.tolist())\n",
    "print(adata_outflow.var.head())\n",
    "\n",
    "# 2. Inflow\n",
    "adata_inflow, _ = construct_inflow_signals_cellchat(\n",
    "    adata,\n",
    "    cellchat_output_key=cellchat_output_key,\n",
    "    model_organism='mouse'\n",
    ")\n",
    "print(\"INFLOW .var columns:\", adata_inflow.var.columns.tolist())\n",
    "print(adata_inflow.var.head())\n",
    "\n",
    "# 3. GEM\n",
    "cfg = FlowSigConfig()\n",
    "adata_gem, _ = construct_gem_expressions(\n",
    "    adata,\n",
    "    config=cfg\n",
    ")\n",
    "print(\"GEM .var columns:\", adata_gem.var.columns.tolist())\n",
    "print(adata_gem.var.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b90b7-3d6d-4bdc-b8dc-5c65e9a93c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = pd.read_csv('cell_names.csv', header=None).squeeze()\n",
    "gene_names = pd.read_csv('gene_names.csv', header=None).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e7a8d-0a3f-412d-b160-ff7c68c51421",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = cell_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5d8ca-2cd8-4dde-b293-98a175105550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_names = gene_names[1:]\n",
    "\n",
    "adata.obs.index = cell_names\n",
    "adata.var.index = gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddbd7f6-34b6-4bc8-a890-ec1c345f9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.index.name = 'Cell_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10e86f-e84e-440e-bad3-a59001f50931",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index.name = 'Gene_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.pp.construct_gems_using_pyliger(adata_onc12,\n",
    "                                n_gems = 10,\n",
    "                                layer_key = 'counts',\n",
    "                                condition_key = condition_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fcc04-1c8a-4eee-95c6-c35cc8727b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12.write('onc_gem12.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b251846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs.pp.construct_flow_expressions(adata_onc12,\n",
    "                                cellchat_output_key=cellchat_output_key,\n",
    "                                model_organism = 'mouse',\n",
    "                                spatial = False,\n",
    "                                method = 'cellchat'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd17b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_onc12.write('onc_cfe12.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42648c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs.pp.determine_informative_variables(\n",
    "    adata_onc12,\n",
    "    spatial       = False,\n",
    "    condition_key = 'orig.ident',\n",
    "    control       = 'onc1',\n",
    "    logfc_thr     = 0.5,\n",
    "    qval_thr      = 0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12.write('onc_div12.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761f216",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.tl.learn_intercellular_flows(\n",
    "    adata_onc12,\n",
    "    condition_key = condition_key,\n",
    "    control       = 'onc1',\n",
    "    use_spatial   = False,\n",
    "    n_jobs        = 32,\n",
    "    n_bootstraps  = 200,\n",
    "    alpha_ci      = 0.05,   # bootstrap 置信区间下限/上限用的 alpha\n",
    "    alpha_inv     = 0.5     # 邀请阈值，例如保留 A 中大于 0.5 的边\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91adabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_sub = 8000\n",
    "idx = np.random.choice(adata.n_obs, size=n_sub, replace=False)\n",
    "adata_sub = adata[idx].copy()\n",
    "\n",
    "# 然后在子集上跑原来的流程\n",
    "fs.pp.determine_informative_variables(\n",
    "    adata_sub,\n",
    "    spatial       = False,\n",
    "    condition_key = 'orig.ident',\n",
    "    control       = 'onc1',\n",
    "    logfc_thr     = 0.5,\n",
    "    qval_thr      = 0.05,\n",
    "    method        = 'wilcoxon'\n",
    ")\n",
    "fs.tl.learn_intercellular_flows(\n",
    "    adata_sub,\n",
    "    condition_key = 'orig.ident',\n",
    "    control       = 'onc1',\n",
    "    use_spatial   = False,\n",
    "    n_jobs        = 16,\n",
    "    n_bootstraps  = 200,     # 少一点\n",
    "    alpha_ci      = 0.05,\n",
    "    alpha_inv     = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. 复制（AnnData.copy() 已经深拷贝 .uns；这里再 copy.deepcopy 保守处理）\n",
    "adata_save = adata_onc12.copy()\n",
    "adata_save.uns = copy.deepcopy(adata_onc12.uns)\n",
    "\n",
    "# 2. 把所有字典键转成字符串\n",
    "def stringify_keys(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): stringify_keys(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [stringify_keys(x) for x in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "adata_save.uns = stringify_keys(adata_save.uns)\n",
    "\n",
    "# 3. 保存\n",
    "out = Path(\"onc_lif12.h5ad\")\n",
    "adata_save.write(out)\n",
    "print(f\"Saved to {out.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_onc12 = sc.read('onc_lif12.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdfc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs.tl.apply_biological_flow(\n",
    "    adata_onc12,\n",
    "    adjacency_key       = 'adjacency',\n",
    "    validated_key       = 'validated'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.tl.filter_low_confidence_edges(\n",
    "    adata_onc12,\n",
    "    edge_threshold       = 0.5,\n",
    "    flowsig_network_key  = 'flowsig_network',\n",
    "    adjacency_key        = 'adjacency_validated',\n",
    "    filtered_key         = 'filtered'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "ident_df = pd.read_csv(\"active_ident.csv\")\n",
    "\n",
    "# 假设 'Cell_ID' 是细胞的名称，将它设为索引\n",
    "ident_df.set_index('Cell_ID', inplace=True)\n",
    "\n",
    "# 确保 adata 和 ident_df 的索引一致（通常是细胞名称）\n",
    "# 将 active.ident 加入到 adata.obs 中\n",
    "adata.uns['active_ident'] = ident_df.loc[adata.obs_names, 'ident_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ce583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "from typing import Union, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7b1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取行名（细胞名称）\n",
    "row_names = adata.obs_names\n",
    "print(\"行名（细胞）：\", row_names)\n",
    "\n",
    "# 获取列名（基因或特征名称）\n",
    "col_names = adata.var_names\n",
    "print(\"列名（基因或特征）：\", col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75323dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['pyliger_info']['n_gems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc12084",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_data = adata.obsm['X_gem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59094a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gem_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10df98",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "module_names = [f\"GEM-{i+1}\" for i in range(10)]\n",
    "gem_df = pd.DataFrame(gem_data, index=row_names, columns=module_names)\n",
    "print(gem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73224e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_df.to_csv(\"gem_df.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196a2aa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata.uns['pyliger_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0964ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.uns['pyliger_info'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073008f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 获取 GEM 表达矩阵\n",
    "X_gem = adata.obsm['X_gem']  # 每个细胞在 GEM 中的表达\n",
    "\n",
    "# 创建一个字典来存储每个 GEM 及其对应的基因\n",
    "gem_genes = {}\n",
    "\n",
    "# 获取基因名称\n",
    "gene_names = adata.var.index.tolist()\n",
    "\n",
    "# 遍历 pyliger_info 中的条件\n",
    "for cond in adata.uns['pyliger_info'].keys():\n",
    "    if cond not in ['n_gems', 'vars']:  # 跳过不相关的键\n",
    "        # 获取当前条件的 W 矩阵\n",
    "        W = adata.uns['pyliger_info'][cond]['W']  # 从每个条件中提取 W 矩阵\n",
    "\n",
    "        # 假设 W 是一个 (num_genes, num_gems) 的矩阵\n",
    "        num_gems = W.shape[1]\n",
    "\n",
    "        for gem_idx in range(num_gems):\n",
    "            # 获取当前 GEM 的权重\n",
    "            gem_weights = W[:, gem_idx]\n",
    "\n",
    "            # 找出权重大于某个阈值的基因索引\n",
    "            threshold = 0  # 可以调整这个阈值\n",
    "            gene_indices = np.where(gem_weights > threshold)[0]\n",
    "\n",
    "            # 获取这些基因的名称和权重\n",
    "            important_genes = [(gene_names[i], gem_weights[i]) for i in gene_indices]\n",
    "\n",
    "            # 按权重排序，获取前 10 个基因\n",
    "            important_genes.sort(key=lambda x: x[1], reverse=True)  # 按权重降序排序\n",
    "            top_genes = important_genes[:20]  # 选择前 10 个基因\n",
    "\n",
    "            # 存储结果\n",
    "            gem_genes[f'{cond}_GEM-{gem_idx + 1}'] = top_genes\n",
    "\n",
    "# 打印每个 GEM 中最重要的十个基因\n",
    "for gem, genes in gem_genes.items():\n",
    "    gene_names_list = [gene[0] for gene in genes]  # 提取基因名称\n",
    "    print(f\"{gem}: {', '.join(gene_names_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d14d6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 获取 GEM 表达矩阵\n",
    "X_gem = adata.obsm['X_gem']  # 每个细胞在 GEM 中的表达\n",
    "\n",
    "# 创建一个字典来存储每个 GEM 及其对应的基因\n",
    "gem_genes = {}\n",
    "\n",
    "# 获取基因名称\n",
    "gene_names = adata.var.index.tolist()\n",
    "\n",
    "# 遍历 pyliger_info 中的条件\n",
    "for cond in adata.uns['pyliger_info'].keys():\n",
    "    if cond not in ['n_gems', 'vars']:  # 跳过不相关的键\n",
    "        # 获取当前条件的 W 矩阵\n",
    "        W = adata.uns['pyliger_info'][cond]['W']  # 从每个条件中提取 W 矩阵\n",
    "\n",
    "        # 假设 W 是一个 (num_genes, num_gems) 的矩阵\n",
    "        num_gems = W.shape[1]\n",
    "\n",
    "        for gem_idx in range(num_gems):\n",
    "            # 获取当前 GEM 的权重\n",
    "            gem_weights = W[:, gem_idx]\n",
    "\n",
    "            # 找出权重大于某个阈值的基因索引\n",
    "            threshold = 0  # 可以调整这个阈值\n",
    "            gene_indices = np.where(gem_weights > threshold)[0]\n",
    "\n",
    "            # 获取这些基因的名称和权重\n",
    "            important_genes = [(gene_names[i], gem_weights[i]) for i in gene_indices]\n",
    "\n",
    "            # 按权重排序，获取前 20 个基因\n",
    "            important_genes.sort(key=lambda x: x[1], reverse=True)  # 按权重降序排序\n",
    "            top_genes = important_genes[:100]  # 选择前 20 个基因\n",
    "\n",
    "            # 存储结果\n",
    "            gem_genes[f'{cond}_GEM-{gem_idx + 1}'] = top_genes\n",
    "\n",
    "# 创建一个 DataFrame 来保存基因和权重数据\n",
    "gene_weight_data = []\n",
    "\n",
    "# 遍历每个 GEM，收集基因和权重\n",
    "for cond in gem_genes.keys():\n",
    "    for gene, weight in gem_genes[cond]:\n",
    "        gene_weight_data.append({'GEM': cond, 'Gene': gene, 'Weight': weight})\n",
    "\n",
    "# 创建 DataFrame\n",
    "gene_weight_df = pd.DataFrame(gene_weight_data)\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "gene_weight_df.to_csv('gem_genes_weights.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7a284",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6798b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from typing import Union, Sequence, List, Tuple, Optional, Iterable\n",
    "from matplotlib.axes import Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04297fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy  \n",
    "from anndata import AnnData\n",
    "fvi_unique = (\n",
    "    adata_onc12.uns['flowsig_network']['flow_var_info']\n",
    "      .groupby(level=0, sort=False)          # 每个 node 一组\n",
    "      .first()                               # 保留第一条（可换成 mean()/median() 等聚合）\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "# 2. 构造一个轻量 AnnData 视图，矩阵沿用原内存\n",
    "adata_view = AnnData(\n",
    "    X      = adata_onc12.X,\n",
    "    obs    = adata_onc12.obs,\n",
    "    var    = adata_onc12.var,\n",
    "    layers = adata_onc12.layers,\n",
    "    obsm   = adata_onc12.obsm,\n",
    "    varm   = adata_onc12.varm,\n",
    "    obsp   = adata_onc12.obsp,\n",
    "    varp   = adata_onc12.varp,\n",
    "    uns    = copy.deepcopy(adata_onc12.uns),       # 仅 .uns 需要深拷贝\n",
    ")\n",
    "adata_view.uns['flowsig_network']['flow_var_info'] = fvi_unique   # 覆盖为唯一索引版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac005d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flow_network = fs.tl.construct_intercellular_flow_network(adata_onc12,\n",
    "                                                        flowsig_network_key = 'flowsig_network',\n",
    "                                                        adjacency_key = 'adjacency_validated_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 深拷贝并清洗 flow_var_info\n",
    "fvi = adata_view.uns['flowsig_network']['flow_var_info']\n",
    "fvi_clean = fvi.copy()\n",
    "\n",
    "# 去空格：索引和 Interaction（如有必要）都 strip\n",
    "idx = fvi_clean.index.to_series().str.strip()\n",
    "fvi_clean.index = idx\n",
    "# 如果 Interaction 里也有空格：\n",
    "# fvi_clean['Interaction'] = fvi_clean['Interaction'].str.strip()\n",
    "\n",
    "# 去重：保留第一次出现\n",
    "fvi_clean = fvi_clean[~fvi_clean.index.duplicated(keep='first')]\n",
    "\n",
    "# 2. 挂回到一个新的 AnnData 视图\n",
    "adata_clean = adata_view.copy()\n",
    "adata_clean.uns = copy.deepcopy(adata_view.uns)\n",
    "adata_clean.uns['flowsig_network']['flow_var_info'] = fvi_clean\n",
    "\n",
    "# 3. **从 fvi_clean 自动生成三组干净的变量列表**\n",
    "inflow_vars  = [node for node, t in zip(fvi_clean.index, fvi_clean['Type']) if t=='inflow']\n",
    "module_vars  = [node for node, t in zip(fvi_clean.index, fvi_clean['Type']) if t=='module']\n",
    "outflow_vars = [node for node, t in zip(fvi_clean.index, fvi_clean['Type']) if t=='outflow']\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# 1. 构造旧→新名称映射（strip 首尾空格）\n",
    "mapping = {node: node.strip() for node in flow_network.nodes()}\n",
    "\n",
    "# 2. 利用 networkx.relabel_nodes 快速重命名\n",
    "flow_network_clean = nx.relabel_nodes(flow_network, mapping, copy=True)\n",
    "\n",
    "# 3. 只保留在 fvi_clean.index（你清洗后）的那些节点\n",
    "keep = set(fvi_clean.index)\n",
    "flow_network_clean = flow_network_clean.subgraph(keep).copy()\n",
    "valid_nodes = set(flow_network_clean.nodes())\n",
    "\n",
    "def filter_vars(lst, valid):\n",
    "    bad = set(lst) - valid\n",
    "    if bad:\n",
    "        print(f\"Dropping {len(bad)} missing nodes:\", bad)\n",
    "    return [n for n in lst if n in valid]\n",
    "\n",
    "inflow_vars  = filter_vars(inflow_vars, valid_nodes)\n",
    "module_vars  = filter_vars(module_vars, valid_nodes)\n",
    "outflow_vars = filter_vars(outflow_vars, valid_nodes)\n",
    "\n",
    "print(f\"→ inflow: {len(inflow_vars)} nodes, module: {len(module_vars)}, outflow: {len(outflow_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ced841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    # 文本字体\n",
    "    'font.size':           12,   # 基本文字大小\n",
    "    'axes.titlesize':      14,   # 标题\n",
    "    'axes.labelsize':      12,   # 坐标轴标签\n",
    "    'xtick.labelsize':     10,   # 刻度文字\n",
    "    'ytick.labelsize':     10,\n",
    "    'legend.fontsize':     10,\n",
    "\n",
    "    # 线条和节点\n",
    "    'lines.linewidth':     1.5,  # 如果 flowsig 用 plot 画边\n",
    "    'lines.markersize':    6,    # 如果你后续有散点\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c6df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import PathCollection\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "\n",
    "fs.pl.plot_intercellular_flows(\n",
    "    adata_clean,\n",
    "    flow_network        = flow_network_clean,\n",
    "    flowsig_network_key = 'flowsig_network',\n",
    "    align_mode          = 'vertical',\n",
    "    inflow_vars         = inflow_vars,\n",
    "    module_vars         = module_vars,\n",
    "    outflow_vars        = outflow_vars,\n",
    "    width_scale         = 1.0,\n",
    "    x_margin_offset     = 0.0,   # ← 左右再留点空\n",
    "    y_margin_offset     = 0.0,   # ← 上下再留点空\n",
    "    ax                  = ax,\n",
    ")\n",
    "for txt in ax.texts:\n",
    "    txt.set_fontsize(8)\n",
    "    txt.set_rotation(0)               # 水平\n",
    "    txt.set_horizontalalignment(\"right\")\n",
    "    \n",
    "# 调整所有文本大小\n",
    "for txt in ax.texts:\n",
    "    x, y = txt.get_position()\n",
    "    txt.set_position((x, y ))\n",
    "\n",
    "# —— 把所有节点圆点缩小一些 —— #\n",
    "# 定义你想要的大小\n",
    "SIZE_IN  = 200\n",
    "SIZE_MOD = 50\n",
    "SIZE_OUT = 50\n",
    "\n",
    "# 重新给每个 PathCollection 定大小\n",
    "for coll in ax.collections:\n",
    "    if not isinstance(coll, PathCollection):\n",
    "        continue\n",
    "    coords = coll.get_offsets()  # numpy array of shape (n_points, 2)\n",
    "    xs = coords[:,0]\n",
    "    coll.set_linewidths(0.66)\n",
    "    # 根据 x 坐标决定这组点是 inflow/module/outflow\n",
    "    if xs.mean() < -0.5:          # 根据你的 X_SPACING 适当调整阈值\n",
    "        coll.set_sizes([SIZE_IN])\n",
    "    elif xs.mean() >  0.5:\n",
    "        coll.set_sizes([SIZE_OUT])\n",
    "    else:\n",
    "        coll.set_sizes([SIZE_MOD])\n",
    "\n",
    "fig.set_figheight(6.4)\n",
    "fig.set_figwidth(6.4)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Inflow',\n",
    "           markerfacecolor='tab:blue', markersize=12),\n",
    "    Line2D([0], [0], marker='v', color='w', label='Module',\n",
    "           markerfacecolor='tab:orange', markersize=12),\n",
    "    Line2D([0], [0], marker='s', color='w', label='Outflow',\n",
    "           markerfacecolor='tab:green', markersize=12)\n",
    "]\n",
    "\n",
    "# 添加图例到已有 ax\n",
    "ax.legend(handles=legend_elements, loc='upper right', title='Node Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c489b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— 2) 调色板补丁 ——#\n",
    "# 推荐直接用布尔索引计算每种类型节点数，避免 query 字符串错误\n",
    "import math\n",
    "fvi = adata_clean.uns['flowsig_network']['flow_var_info']\n",
    "n_inflow  = (fvi['Type'] == 'inflow').sum()\n",
    "n_module  = (fvi['Type'] == 'module').sum()\n",
    "n_outflow = (fvi['Type'] == 'outflow').sum()\n",
    "n_nodes   = n_inflow + n_module + n_outflow\n",
    "\n",
    "# 生成浅色 Set2 调色板，长度至少 n_nodes\n",
    "base    = sns.color_palette(\"Set2\", 20)\n",
    "repeat  = math.ceil(n_nodes / len(base))\n",
    "fsp.palette_network = (base * repeat)[:n_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 恢复 Matplotlib 的 rcParams 到默认值\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# 2) 如果你覆盖过 palette_network，也一起恢复\n",
    "import flowsig.plotting._plotting as fsp\n",
    "import importlib\n",
    "importlib.reload(fsp)   # 重载模块，palette_network 会回到源码里定义的那个\n",
    "\n",
    "# 3) 恢复 networkx 的 multipartite_layout 到官方默认\n",
    "import networkx.drawing.layout as layout\n",
    "import importlib\n",
    "importlib.reload(layout)\n",
    "\n",
    "# 4) 再次重载 FlowSig plotting，确保它拿到网络画图库刚刚重载的版本\n",
    "importlib.reload(fsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# flow_network_clean 是一个 NetworkX 图\n",
    "n_nodes = len(flow_network_clean.nodes)\n",
    "print(\"需要颜色数:\", n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e7fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "\n",
    "fs.pl.plot_intercellular_flows(\n",
    "    adata_clean,\n",
    "    flow_network        = flow_network_clean,\n",
    "    flowsig_network_key = 'flowsig_network',\n",
    "    module_vars         = ['GEM-3'],\n",
    "    align_mode          = 'vertical',\n",
    "    width_scale         = 0.66,\n",
    "    x_margin_offset     = 0.08,   # ← 左右再留点空\n",
    "    y_margin_offset     = 0.0,   # ← 上下再留点空\n",
    "    ax                  = ax,\n",
    ")\n",
    "for txt in ax.texts:\n",
    "    txt.set_fontsize(8)\n",
    "    txt.set_rotation(0)               # 水平\n",
    "    txt.set_horizontalalignment(\"right\")\n",
    "    \n",
    "# 调整所有文本大小\n",
    "for txt in ax.texts:\n",
    "    x, y = txt.get_position()\n",
    "    txt.set_position((x-0.02, y ))\n",
    "\n",
    "# —— 把所有节点圆点缩小一些 —— #\n",
    "# 定义你想要的大小\n",
    "SIZE_IN  = 200\n",
    "SIZE_MOD = 50\n",
    "SIZE_OUT = 50\n",
    "\n",
    "# 重新给每个 PathCollection 定大小\n",
    "for coll in ax.collections:\n",
    "    if not isinstance(coll, PathCollection):\n",
    "        continue\n",
    "    coords = coll.get_offsets()  # numpy array of shape (n_points, 2)\n",
    "    xs = coords[:,0]\n",
    "    coll.set_linewidths(0.66)\n",
    "    # 根据 x 坐标决定这组点是 inflow/module/outflow\n",
    "    if xs.mean() < -0.5:          # 根据你的 X_SPACING 适当调整阈值\n",
    "        coll.set_sizes([SIZE_IN])\n",
    "    elif xs.mean() >  0.5:\n",
    "        coll.set_sizes([SIZE_OUT])\n",
    "    else:\n",
    "        coll.set_sizes([SIZE_MOD])\n",
    "\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fad70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a458c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fvi = adata.uns['flowsig_network']['flow_var_info']\n",
    "\n",
    "# 看前几行的数据长什么样\n",
    "print(\"=== 前 5 行 ===\")\n",
    "print(fvi.head(), \"\\n\")\n",
    "\n",
    "# 看一下它的列名\n",
    "print(\"=== 列名 ===\")\n",
    "print(fvi.columns.tolist(), \"\\n\")\n",
    "\n",
    "# 看一下索引前 20 个节点的名字\n",
    "print(\"=== 索引示例 ===\")\n",
    "for idx in fvi.index[:20]:\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a4e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. 取出 flow_var_info\n",
    "fvi = adata_view.uns['flowsig_network']['flow_var_info']\n",
    "\n",
    "# 2. 查看索引是否唯一\n",
    "print(\"索引是否唯一？\", fvi.index.is_unique)\n",
    "\n",
    "# 3. 显示所有 flow_var_info\n",
    "print(\"\\n=== 全部 flow_var_info ===\")\n",
    "print(fvi.to_string())        # Jupyter 环境下直接 fvi 也会渲染成表格\n",
    "\n",
    "# 4. 找出并显示索引重复的条目\n",
    "duplicates = fvi[fvi.index.duplicated(keep=False)]\n",
    "print(\"\\n=== 索引重复的 flow_var_info 条目 ===\")\n",
    "print(duplicates.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96812c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[\"cellchat_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cc2be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 0. 假设 adata 已经读入，cellchat_output 在 adata.uns\n",
    "cellchat = adata.uns[\"cellchat_output\"]      # dict: time_key → DataFrame\n",
    "\n",
    "# 1. 时间标签与小时数映射\n",
    "time_map = {\n",
    "    \"onc1\": \"Control\",    # Control\n",
    "    \"onc2\": \"ONC 2h\",    # ONC 2h\n",
    "    \"onc3\": \"ONC 8h\",    # ONC 8h\n",
    "    \"onc4\": \"ONC 1d\",    # ONC 1d  \n",
    "    \"onc5\": \"ONC 3d\",    # ONC 3d\n",
    "    \"onc6\": \"ONC 7d\",    # ONC 7d\n",
    "}\n",
    "\n",
    "# 2. 抽取 RGC ↔ Endothelial（或你需要的细胞对）互作并聚合\n",
    "records = []\n",
    "for key, df in cellchat.items():\n",
    "    if key not in time_map: continue\n",
    "    t_h = time_map[key]\n",
    "    sub = df[\n",
    "        ((df.source == \"RGC\") & (df.target == \"Microglia_Activated\")) |\n",
    "        ((df.source == \"Microglia_Activated\") & (df.target == \"RGC\"))\n",
    "    ].copy()\n",
    "    if sub.empty: continue\n",
    "    agg = (\n",
    "        sub.groupby([\"ligand\",\"receptor\"])[\"prob\"]\n",
    "           .sum().reset_index()\n",
    "    )\n",
    "    agg[\"time_h\"] = t_h\n",
    "    agg[\"pair\"]   = agg[\"ligand\"] + \" - \" + agg[\"receptor\"]\n",
    "    records.append(agg[[\"pair\",\"time_h\",\"prob\"]])\n",
    "\n",
    "if not records:\n",
    "    raise ValueError(\"在 RGC ↔ Endothelial 之间没有找到任何交互数据。\")\n",
    "long_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "# 3. 透视成长×宽表：行=pair，列=time_h\n",
    "pivot = long_df.pivot_table(\n",
    "    index=\"pair\", columns=\"time_h\", values=\"prob\", fill_value=0\n",
    ")\n",
    "pivot = pivot.reindex(columns=[0,2,8,24,72,168], fill_value=0)\n",
    "\n",
    "# ——— 以下开始筛选 ———\n",
    "\n",
    "# 1) 过滤：只要求 Control(0h) == 0\n",
    "mask_initial_zero = (pivot[0] == 0)\n",
    "\n",
    "# 2) 后续时点\n",
    "time_pts = [8,24,72,168]\n",
    "\n",
    "# 3) 计算增量\n",
    "deltas = {t: pivot[t] - pivot[0] for t in time_pts}\n",
    "\n",
    "# 4) 筛选：这四个时点 都要增量 > 0\n",
    "mask_increase = pd.concat([deltas[t] > 0 for t in time_pts], axis=1).all(axis=1)\n",
    "\n",
    "# 5) 合并条件\n",
    "mask = mask_initial_zero & mask_increase\n",
    "\n",
    "# 6) 提取完整六个时点的原始值\n",
    "cols_all = [0,2] + time_pts\n",
    "inc_all = pivot.loc[mask, cols_all].copy()\n",
    "\n",
    "# 7) 计算 Δ 列 & sum(Δ)\n",
    "for t in time_pts:\n",
    "    inc_all[f\"Δ{t}h\"] = deltas[t][mask]\n",
    "inc_all[\"sum(Δ)\"] = inc_all[[f\"Δ{t}h\" for t in time_pts]].sum(axis=1)\n",
    "\n",
    "# 8) 排序并展示\n",
    "inc_all = inc_all.sort_values(\"sum(Δ)\", ascending=False)\n",
    "print(\"Pairs with Control=0 and increasing at 8h,24h,72h,168h:\")\n",
    "display(inc_all)\n",
    "\n",
    "print(\"\\nTop 5:\")\n",
    "top5 = inc_all.head(5)\n",
    "display(top5)\n",
    "\n",
    "# 9) 给 Top5 画折线图（包括 0h,2h 在内）\n",
    "labels = [\"0 h\",\"2 h\",\"8 h\",\"24 h\",\"72 h\",\"168 h\"]\n",
    "pos    = np.arange(len(cols_all))\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=300)\n",
    "for pair, row in top5.iterrows():\n",
    "    y = row[cols_all].values.astype(float)\n",
    "    plt.plot(pos, y, marker='o', label=pair)\n",
    "\n",
    "plt.xticks(pos, labels)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Aggregated probability\")\n",
    "plt.title(\"Top 5 ligand–receptor pairs\\n(Control = 0, then increasing)\")\n",
    "plt.legend(bbox_to_anchor=(1,0.5), fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 pivot 已经是 RGC↔Microglia_Activated 的 “pair × time_h” 矩阵\n",
    "# 列名为 [0, 2, 8, 24, 72, 168]，0 表示 Control, 后面分别是 2h,8h,1d,3d,7d\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) 计算每个时间点相对于 Control 的增量\n",
    "time_pts = [2, 8, 24, 72, 168]\n",
    "deltas = {t: pivot[t] - pivot[0] for t in time_pts}\n",
    "\n",
    "# 2) 筛选：所有时间点都增量 > 0\n",
    "mask = pd.concat([deltas[t] > 0 for t in time_pts], axis=1).all(axis=1)\n",
    "inc_all = pivot.loc[mask, [0] + time_pts].copy()\n",
    "\n",
    "# 3) 添加 Δ 列和总增幅\n",
    "for t in time_pts:\n",
    "    inc_all[f\"Δ{t}h\"] = deltas[t][mask]\n",
    "inc_all[\"sum(Δ)\"] = inc_all[[f\"Δ{t}h\" for t in time_pts]].sum(axis=1)\n",
    "\n",
    "# 4) 排序并展示\n",
    "inc_all = inc_all.sort_values(\"sum(Δ)\", ascending=False)\n",
    "print(\"Pairs increasing at all time points vs. Control:\")\n",
    "display(inc_all)\n",
    "\n",
    "# （可选）只看 Top5\n",
    "print(\"Top 5:\")\n",
    "display(inc_all.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# —— 假设 pivot 已经是 “pair × time” 矩阵，列 [0,2,8,24,72,168] —— \n",
    "\n",
    "# 1. 关注的四个时点\n",
    "time_pts = [8, 24, 72, 168]\n",
    "\n",
    "# 2. 计算增量\n",
    "deltas = {t: pivot[t] - pivot[0] for t in time_pts}\n",
    "\n",
    "# 3. 筛选：这四个时点增量 > 0，并且 Control(0) == 0\n",
    "mask = (\n",
    "    pd.concat([deltas[t] > 0 for t in time_pts], axis=1)\n",
    "      .all(axis=1)\n",
    ") & (pivot[0] == 0)\n",
    "\n",
    "# 4. 取出 Control + 2h + 8h/24h/72h/168h 的原始 prob\n",
    "cols = [0, 2] + time_pts\n",
    "inc_all = pivot.loc[mask, cols].copy()\n",
    "\n",
    "# 5. 再生成 Δ8h,Δ24h,Δ72h,Δ168h，并计算和\n",
    "for t in time_pts:\n",
    "    inc_all[f\"Δ{t}h\"] = deltas[t][mask]\n",
    "inc_all[\"sum(Δ)\"] = inc_all[[f\"Δ{t}h\" for t in time_pts]].sum(axis=1)\n",
    "\n",
    "# 6. 排序 & 展示\n",
    "inc_all = inc_all.sort_values(\"sum(Δ)\", ascending=False)\n",
    "print(\"Pairs with initial=0 and increasing at 8h,24h,72h,168h, with 2h re-added:\")\n",
    "display(inc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 inc_all 已经准备好，index 是 “ligand - receptor”，\n",
    "# 列名包含 [0,2,8,24,72,168]，分别是 Control,2h,8h,1d,3d,7d。\n",
    "\n",
    "# 1) 定义原始时间点和等距位置\n",
    "time_pts    = [0, 2, 8, 24, 72, 168]\n",
    "time_labels = [\"Control\", \"2 h\", \"8 h\", \"1 d\", \"3 d\", \"7 d\"]\n",
    "pos         = list(range(len(time_pts)))    # [0,1,2,3,4,5]\n",
    "\n",
    "# 2) 绘制折线\n",
    "plt.figure(figsize=(10,5),dpi=300)\n",
    "for pair, row in inc_all.iterrows():\n",
    "    y = row[time_pts].values.astype(float)\n",
    "    plt.plot(pos, y, marker=\"o\", label=pair)\n",
    "\n",
    "# 3) 设置等距的刻度和标签\n",
    "plt.xticks(pos, time_labels)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Aggregated probability\")\n",
    "plt.title(\"Ligand–Receptor Pairs Increasing at All Time Points\")\n",
    "plt.grid(False)\n",
    "\n",
    "# 4) 图例放在右侧\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0137706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.obs.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d178bc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "df = pd.read_excel('GEM3_Flows_Expanded.xlsx', header=[0,1])\n",
    "in_df  = df['In']\n",
    "out_df = df['Out']\n",
    "\n",
    "# 2. 获取时间点\n",
    "timepoints = [tp for tp in in_df.columns if in_df[tp].notna().any()]\n",
    "for tp in out_df.columns:\n",
    "    if tp not in timepoints and out_df[tp].notna().any():\n",
    "        timepoints.append(tp)\n",
    "n_tp = len(timepoints)\n",
    "\n",
    "# 3. 收集信号坐标\n",
    "def get_positions(net_df, z):\n",
    "    pos = {}\n",
    "    for r, row in net_df.iterrows():\n",
    "        for xi, tp in enumerate(timepoints):\n",
    "            val = row.get(tp)\n",
    "            if pd.notna(val):\n",
    "                sig = str(val)\n",
    "                pos.setdefault(sig, []).append((xi, r, z))\n",
    "    return pos\n",
    "\n",
    "in_pos  = get_positions(in_df, 1)\n",
    "out_pos = get_positions(out_df, 0)\n",
    "all_pos = {**in_pos, **out_pos}\n",
    "\n",
    "# 4. Nature 调色板\n",
    "palette = [\n",
    "    '#3E5481','#2C7FB8','#6BAED6','#B2D8E8','#006837',\n",
    "    '#66A61E','#B15928','#E6550D','#FD8D3C','#FDD0A2','#756BB1'\n",
    "]\n",
    "\n",
    "# 5. 绘图\n",
    "fig = plt.figure(figsize=(12,24), dpi=300)\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "ax.yaxis._axinfo[\"grid\"]['linewidth'] = 0\n",
    "\n",
    "# 轴标签与刻度\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Signal Index')\n",
    "ax.set_zlabel('Network Level')\n",
    "ax.set_xticks(range(n_tp))\n",
    "ax.set_xticklabels(timepoints)\n",
    "ax.set_zticks([0,1])\n",
    "ax.set_zticklabels(['Out','In'])\n",
    "\n",
    "# 长方体比例: X:Y:Z = 3:1:1\n",
    "ax.set_box_aspect((3,6,3))\n",
    "\n",
    "# 文本偏移与旋转\n",
    "\n",
    "for i, (sig, coords) in enumerate(all_pos.items()):\n",
    "    color = palette[i % len(palette)]\n",
    "    coords_sorted = sorted(coords, key=lambda x: (x[2], x[0]))  # 按网络再按时间排序\n",
    "\n",
    "    # 分别绘制 In (z=1) 和 Out (z=0)\n",
    "    for z_level, marker in [(1, 'o'), (0, 's')]:\n",
    "        pts = [(x,y,z) for x,y,z in coords_sorted if z == z_level]\n",
    "        if len(pts) > 1:\n",
    "            xs, ys, zs = zip(*pts)\n",
    "            ax.plot(xs, ys, zs,\n",
    "                    marker=marker, markersize=6,\n",
    "                    linewidth=1.5, color=color)\n",
    "            for x, y, z in pts:\n",
    "                xl, yl, zl = x + dx, y + dy, z\n",
    "                ax.plot([x, xl], [y, yl], [z, zl],\n",
    "                        color=color, linewidth=0.5)\n",
    "                ax.text(xl, yl, zl, sig,\n",
    "                        size=6, ha='right', va='center',\n",
    "                        rotation=rot)\n",
    "        elif len(pts) == 1:\n",
    "            x, y, z = pts[0]\n",
    "            ax.scatter(x, y, z, s=30, c=color, marker=marker)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce43ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 准备 GEM6 数据 ---\n",
    "# 1. 读取 GEM2（双行表头）\n",
    "file_path = 'GEM2_Flows_Expanded.xlsx'\n",
    "df2 = pd.read_excel(file_path, header=[0,1])\n",
    "\n",
    "# 2. 拆分 In/Out 子表\n",
    "in_df  = df2['In']\n",
    "out_df = df2['Out']\n",
    "\n",
    "# 3. 提取时间点列表（使用 Out 表的列，去除重复的 “7d.1”）\n",
    "timepoints = out_df.columns.tolist()\n",
    "\n",
    "# 4. 按时间点聚合 Ligands/Receptors\n",
    "ligands   = []\n",
    "receptors = []\n",
    "for tp in timepoints:\n",
    "    # In 流入信号\n",
    "    li = in_df[tp].dropna().astype(str).tolist()\n",
    "    ligands.append(', '.join(li))\n",
    "    # Out 流出信号\n",
    "    ro = out_df[tp].dropna().astype(str).tolist()\n",
    "    receptors.append(', '.join(ro))\n",
    "\n",
    "# 5. 构建 data 字典\n",
    "data = {\n",
    "    'Timepoint':  timepoints,\n",
    "    'Ligands':    ligands,\n",
    "    'Receptors':  receptors\n",
    "}\n",
    "\n",
    "# 6. 转为 DataFrame 并预览\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 拆分为列表 ---\n",
    "df['Ligands']   = df['Ligands'].apply(lambda s: [it.strip() for it in re.split(r'[;,；]\\s*', s) if it.strip()])\n",
    "df['Receptors'] = df['Receptors'].apply(lambda s: [it.strip() for it in re.split(r'[;,；]\\s*', s) if it.strip()])\n",
    "\n",
    "# --- 构造出现索引 ---\n",
    "def build_appearances(col):\n",
    "    app = {}\n",
    "    for ti, row in df.iterrows():\n",
    "        for sig in row[col]:\n",
    "            app.setdefault(sig, []).append(ti)\n",
    "    return app\n",
    "\n",
    "in_app  = build_appearances('Ligands')\n",
    "out_app = build_appearances('Receptors')\n",
    "\n",
    "def build_appearances(col):\n",
    "    app = {}\n",
    "    for ti, row in df.iterrows():\n",
    "        for sig in row[col]:\n",
    "            app.setdefault(sig, []).append(ti)\n",
    "    return app\n",
    "\n",
    "in_app  = build_appearances('Ligands')\n",
    "out_app = build_appearances('Receptors')\n",
    "\n",
    "# --- 统计 & 首次出现 & 最长连续 ---\n",
    "def max_consecutive(idx_list):\n",
    "    if not idx_list: return 0\n",
    "    idxs = sorted(set(idx_list))\n",
    "    cur = best = 1\n",
    "    for a, b in zip(idxs, idxs[1:]):\n",
    "        if b == a+1:\n",
    "            cur += 1\n",
    "        else:\n",
    "            cur = 1\n",
    "        best = max(best, cur)\n",
    "    return best\n",
    "\n",
    "records = []\n",
    "for sig in sorted(set(in_app) | set(out_app)):\n",
    "    idx_in  = sorted(set(in_app.get(sig, [])))\n",
    "    idx_out = sorted(set(out_app.get(sig, [])))\n",
    "    tot_in  = len(idx_in)\n",
    "    tot_out = len(idx_out)\n",
    "    # 计算最长连续\n",
    "    con_in  = max_consecutive(idx_in)\n",
    "    con_out = max_consecutive(idx_out)\n",
    "    # 只保留没有断档的信号序列（且至少出现 2 次）\n",
    "    if (con_in == tot_in and tot_in > 1) or (con_out == tot_out and tot_out > 1):\n",
    "        first = min(idx_in + idx_out)\n",
    "        records.append({\n",
    "            'Signal':       sig,\n",
    "            'First_Appear': first,\n",
    "            'In_Consec':    con_in if con_in == tot_in else 0,\n",
    "            'Out_Consec':   con_out if con_out == tot_out else 0\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(records)\n",
    "# 按首次出现升序排列\n",
    "stats_df.sort_values('First_Appear', inplace=True)\n",
    "stats_df.reset_index(drop=True, inplace=True)\n",
    "stats_df = stats_df[(stats_df['In_Consec'] > 1) | (stats_df['Out_Consec'] > 1)]\n",
    "# --- 分组边界 ---\n",
    "group_sizes = stats_df['First_Appear'].value_counts().sort_index().cumsum()\n",
    "group_labels = [timepoints[i] for i in group_sizes.index]\n",
    "\n",
    "# --- 可视化 ---\n",
    "fig, ax = plt.subplots(figsize=(6,6),dpi =300)\n",
    "x = np.arange(len(stats_df))\n",
    "w = 0.4\n",
    "\n",
    "ax.bar(x,       stats_df['In_Consec'],  w, label='In',  color='tab:orange')\n",
    "ax.bar(x + w,   stats_df['Out_Consec'], w, label='Out', color='tab:red')\n",
    "\n",
    "# 绘制分隔线 & 标注组\n",
    "for b in group_sizes[:-1]:\n",
    "    ax.axvline(b - 0.5, color='grey', linewidth=1)\n",
    "start = 0\n",
    "for size, label in zip(group_sizes, group_labels):\n",
    "    mid = (start + size - 1) / 2\n",
    "    ax.text(mid, ax.get_ylim()[1] + 0.1, label,\n",
    "            ha='center', va='bottom', weight='bold')\n",
    "    start = size\n",
    "\n",
    "ax.set_xticks(x + w/2)\n",
    "ax.set_xticklabels(stats_df['Signal'], rotation=90)\n",
    "ax.set_ylabel('Max Consecutive Timepoints')\n",
    "ax.set_title('GEM2 Consecutive Appearance, Grouped by First Appearance')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e2c8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GEM2 时间点与数据集构建\n",
    "\n",
    "# 1. 时间点列表\n",
    "timepoints = ['2 h', '8 h', '1 d', '3 d', '7 d']\n",
    "\n",
    "# 2. 原始数据字典\n",
    "data = {\n",
    "    'Timepoint': timepoints,\n",
    "    'Ligands': [\n",
    "        'Ocln, Cd38',\n",
    "        'Robo2, Plxna4, Notch1, Nlgn1, Grm8, Grm7, Grik2+Grik5, Grik2+Grik4, Grik2, Flt1, Acvr1+Tgfbr1',\n",
    "        'Unc5c, Tgfbr1+Tgfbr2, Tek, Ptprz1, Ptprd, Pdgfrb, Ntrk3, Plxna2, Plxna4, Notch2, Nectin3, Mertk, Itgav+Itgb8, Itgav+Itgb5, Itgav+Itgb1, Itga9+Itgb1, Itga8+Itgb1, Igf1r, Grm8, Grin1+Grin2b, Grik3+Grik5, Grik3+Grik4, Grik1+Grik5, Grik1+Grik4, Flt1, Fgfr1, Epha3, Egfr, Dag1, Csf1r, Clstn1, Chrna7, Cd36, Bsg, Bmpr1b+Bmpr2, Bmpr1a+Bmpr2, Adgrl2, Acvr1+Tgfbr1, Acvr1+Bmpr2, Acvr1+Acvr2a',\n",
    "        'Vldlr, Trem2+Tyrobp, Ptprm, Ptprd, Plxna4, Notch2, Kdr, Itgav+Itgb8, Itga5+Itgb1, Itga4+Itgb1, Fzd6, Flt1, Clstn2, Clstn1',\n",
    "        'Unc5c, Tgfbr1+Tgfbr2, Plxna4, Pdgfrb, Nectin3, Ncam2, Ncam1, Itgav+Itgb5, Itgav+Itgb1, Grm8, Gabra2, Cx3cr1, Csf1r, Clstn2, Bsg'\n",
    "    ],\n",
    "    'Receptors': [\n",
    "        'Col9a1',  # 无明确标注\n",
    "        'Tenm3, Pdgfd, Nrxn3, Nrxn1, Nrg3, Nfasc, Lrrtm4, Lrrc4c, Lama2, Flrt2, Cx3cr1, Col9a1, Col4a5, Col4a2, Col4a1, Cdh2, Cadm1, C1ql1, Bdnf',\n",
    "        'Vtn, Tulp1, Sema6a, Sdc2, Prnp, Ntn4, Mpzl1, Lamc1, Jam2, Flrt2, Col2a1, Bmp5',\n",
    "        'Tulp1, Sema6a, Pecam1, Nfasc, Mpzl1, Kitl, Col4a6, Col4a1, C1ql1',\n",
    "        'Thy1, Pros1, Ppia, Lrfn5, Cx3cl1, Col9a1, Col2a1, Cdh2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 3. 转为 DataFrame 示例\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 拆分为列表 ---\n",
    "df['Ligands']   = df['Ligands'].apply(lambda s: [it.strip() for it in re.split(r'[;,；]\\s*', s) if it.strip()])\n",
    "df['Receptors'] = df['Receptors'].apply(lambda s: [it.strip() for it in re.split(r'[;,；]\\s*', s) if it.strip()])\n",
    "\n",
    "# --- 构造出现索引 ---\n",
    "def build_appearances(col):\n",
    "    app = {}\n",
    "    for ti, row in df.iterrows():\n",
    "        for sig in row[col]:\n",
    "            app.setdefault(sig, []).append(ti)\n",
    "    return app\n",
    "\n",
    "in_app  = build_appearances('Ligands')\n",
    "out_app = build_appearances('Receptors')\n",
    "\n",
    "# --- 统计 & 首次出现 & 最长连续 ---\n",
    "def max_consecutive(idx_list):\n",
    "    if not idx_list: return 0\n",
    "    idxs = sorted(set(idx_list))\n",
    "    cur = best = 1\n",
    "    for a, b in zip(idxs, idxs[1:]):\n",
    "        if b == a+1:\n",
    "            cur += 1\n",
    "        else:\n",
    "            cur = 1\n",
    "        best = max(best, cur)\n",
    "    return best\n",
    "\n",
    "records = []\n",
    "for sig in sorted(set(in_app) | set(out_app)):\n",
    "    idx_in  = sorted(set(in_app.get(sig, [])))\n",
    "    idx_out = sorted(set(out_app.get(sig, [])))\n",
    "    tot_in  = len(idx_in)\n",
    "    tot_out = len(idx_out)\n",
    "    # 计算最长连续\n",
    "    con_in  = max_consecutive(idx_in)\n",
    "    con_out = max_consecutive(idx_out)\n",
    "    # 只保留没有断档的信号序列（且至少出现 2 次）\n",
    "    if (con_in == tot_in and tot_in > 1) or (con_out == tot_out and tot_out > 1):\n",
    "        first = min(idx_in + idx_out)\n",
    "        records.append({\n",
    "            'Signal':       sig,\n",
    "            'First_Appear': first,\n",
    "            'In_Consec':    con_in if con_in == tot_in else 0,\n",
    "            'Out_Consec':   con_out if con_out == tot_out else 0\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(records)\n",
    "# 按首次出现升序排列\n",
    "stats_df.sort_values('First_Appear', inplace=True)\n",
    "stats_df.reset_index(drop=True, inplace=True)\n",
    "stats_df = stats_df[(stats_df['In_Consec'] > 1) | (stats_df['Out_Consec'] > 1)]\n",
    "# --- 分组边界 ---\n",
    "group_sizes = stats_df['First_Appear'].value_counts().sort_index().cumsum()\n",
    "group_labels = [timepoints[i] for i in group_sizes.index]\n",
    "\n",
    "# --- 可视化 ---\n",
    "fig, ax = plt.subplots(figsize=(6,6),dpi =300)\n",
    "x = np.arange(len(stats_df))\n",
    "w = 0.4\n",
    "\n",
    "ax.bar(x,       stats_df['In_Consec'],  w, label='In',  color='tab:orange')\n",
    "ax.bar(x + w,   stats_df['Out_Consec'], w, label='Out', color='tab:red')\n",
    "\n",
    "# 绘制分隔线 & 标注组\n",
    "firsts = stats_df['First_Appear'].values\n",
    "# diff != 0 的地方就是新组开始，在它之后画线\n",
    "boundaries = np.where(np.diff(firsts) != 0)[0] + 1\n",
    "\n",
    "# 画分隔线\n",
    "for b in boundaries:\n",
    "    ax.axvline(b - 0.5, color='grey', linewidth=1)\n",
    "\n",
    "# 画组标签\n",
    "start = 0\n",
    "for b in np.append(boundaries, len(stats_df)):\n",
    "    # 组从 start 到 b-1\n",
    "    mid = (start + (b-1)) / 2\n",
    "    label = timepoints[stats_df.loc[start, 'First_Appear']]\n",
    "    ax.text(mid, ax.get_ylim()[1] + 0.1, label,\n",
    "            ha='center', va='bottom', weight='bold')\n",
    "    start = b\n",
    "\n",
    "ax.set_xticks(x + w/2)\n",
    "ax.set_xticklabels(stats_df['Signal'], rotation=90)\n",
    "ax.set_ylabel('Max Consecutive Timepoints')\n",
    "ax.set_title('GEM6 Consecutive Appearance, Grouped by First Appearance')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
